import pefile
import sys
import distorm3
import re
import os
import csv
import pandas as pd
import numpy as np
import time
from hashlib import sha1
from hashlib import sha256
from hashlib import sha512
from hashlib import md5

start = time.time()
API_count = [0,0,0]

def get_info(sample_path):
    pe = pefile.PE(sample_path)
    pe.parse_data_directories()
    R_list = []

    try:
        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            DC_entry = entry.dll.decode('utf-8')
            R_list.append(DC_entry)

            API_count[0] += 1

            for imp in entry.imports:
                DC_imp = imp.name.decode('utf-8')
                R_list.append(DC_imp)

                API_count[1] += 1
    except:
        pass

    # try:
    #     for exp in pe.DIRECTORY_ENTRY_EXPORT.symbols:
    #         DC_exp = exp.name.decode('utf-8')
    #         R_list.append(DC_exp)

    #         API_count[2] += 1
    # except:
    #     pass

    return R_list

## load file area change ##
path = '/'
allfile = os.listdir(path)

List_File = pd.read_csv('2019(all)_2020(all)_ABCD.csv')
R_List = List_File['R_List']
R_arr = np.array(R_List)

count = 0
search_result = []

for onefile in allfile:
    file_result = path + onefile
    get_info(file_result)
    L_arr = np.array(get_info(file_result))

    search = []
    search.append(onefile)
    for i in R_arr:
        if i not in L_arr:
            search.append(0)
        else:
            search.append(1)

    # search.append(1)
    search_result.append(search)

    count += 1
    if count % 100 == 0:
        print(count)

## save csv change name ##
A1 = ['file_name']
# A2 = ['class']
columns_name = np.concatenate((A1, R_arr))

df_R= pd.DataFrame(search_result)
df_R.columns = [columns_name]
df_R.to_csv('.csv', index=False)

print('API_count : ' + str(API_count))
print("time :", time.time() - start)
