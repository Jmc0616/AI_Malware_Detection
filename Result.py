import pefile
import sys
import distorm3
from hashlib import sha1
from hashlib import sha256
from hashlib import sha512
from hashlib import md5
import re
import os
import csv
import pandas as pd
import numpy as np
import collections
import time

start = time.time()
API_count = [0,0]
IMP_list = {}
EXP_list = {}

def get_info(sample_path):
    pe = pefile.PE(sample_path)
    pe.parse_data_directories()
    api_list = []

    try:
        for entry in pe.DIRECTORY_ENTRY_IMPORT:
          for imp in entry.imports:
            DC_imp = imp.name.decode('utf-8')
            api_list.append(DC_imp)

            API_count[0] += 1
    except:
        pass

    try:
        for exp in pe.DIRECTORY_ENTRY_EXPORT.symbols:
            DC_exp = exp.name.decode('utf-8')
            api_list.append(DC_exp)

            API_count[1] += 1
    except:
        pass

    return api_list

path = 'C:/Users/skand/Desktop/1st_problem_set/'
allfile = os.listdir(path)

csv_file = pd.read_csv('select.csv')
IAT = csv_file['IAT_Name']
IAT_O = IAT.dropna(axis=0)
arr = np.array(IAT_O)

columns_add1 = ['filename']
columns_name = np.concatenate((columns_add1, IAT_O))

count = 0
search_result = []

for onefile in allfile:
    file_result = path + onefile
    get_info(file_result)
    file_result_arr = np.array(get_info(file_result))

    count += 1

    if count % 100 == 0:
        print('---------- ' + str(count) + ' ----------')

    search = []
    search.append(onefile)

    for i in arr:
        if i not in file_result_arr:
            search.append(0)
        else:
            search.append(1)

    search_result.append(search)

search_result_df = pd.DataFrame(search_result)
search_result_df.columns = [columns_name]
search_result_df.to_csv('1st_problem_set_API.csv', index=False)

print(API_count)
print("time :", time.time() - start)